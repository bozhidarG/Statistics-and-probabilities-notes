---Тестване на хипотези--- Hypothesis testing

При тестването на хипотези предполагаме хипотеза (т.н. нулева хипотеза), след което изчисляваме колко вероятно е тя да бъде вярна.

R разполага с 3 функции за построяване и проверка на хипотеза.
prop.test -> когато данните ни са пропорционални
t.test -> когато данните ни са с нормално разпределение
wilcox.test -> когато не попадаме в горните 2 случая

Примери:

Пропорция:
Събираме 100 дини. Виждаме, че 5 от тях са изгнили. Като всеки съвестен диньопроизводител си даваме сметка, че ако 11% от дините ни са изгнили, то тогава няма да имаме достатъчно чиста печалба за всичките ни нужди.
Нека проверим, дали има за какво да се притесняваме..
prop.test(5,100, p=0.11, alternative="less")

	1-sample proportions test with continuity correction

data:  5 out of 100, null probability 0.11
X-squared = 3.0899, df = 1, p-value = 0.03939
alternative hypothesis: true p is less than 0.11
95 percent confidence interval:
 0.0000000 0.1055372
sample estimates:
   p 
0.05 

Интерпретация на резултата:
с 95% увереност може да твърдим, че изгнилите дини ще са между 0 и 10 процента.
Тъй като p-value<0.05, отхвърляме нулевата хипотеза, която е, че 11% от цялата реколта с дини ще е изгнила и приемаме алтернативната, която е, че по-малко от 11 процента от реколтата с дини ще е изгнила и си отдъхваме спокойно.

Нормално разпределение:
Биолог се заинтересовал, дали ако третира слънчогледи с екстракт от Vinca minor (вид растение) ще повлияе на височината на растението. За целта взел 33 слънчогледа. Очакваният резултат е средната височина на слънчогледите, която попринцип е 15.7, да намалее.
Получените резултати са следните:
11.5 11.8 15.7 16.1 14.1 10.5 15.2 19.0 12.8 12.4 19.2 13.5 16.5 13.5 14.4 16.7	10.9 13.0 15.1 17.1 13.3 12.4 8.5 14.3 12.9 11.1 15.0 13.3 15.8 13.5 9.3 12.2 10.3

Главен проблем:
Как да разберем, че данните ни следват нормално разпределение? 

Начин 1, метод на око:
hist(x) #горе-долу виждаме, че следват нормално разпределение

qqnorm(x,main='Example 01'); #нарежда данните спрямо квантила, в който се намират.
qqline(x)
Разчитане на графиката: Ако несвързания граф прилича на права линия, то данните са приблизително нормално разпределени.
По ординатата са нашите стойности. По абсцисата са теоретичните квантили на нормалното разпределение.
С други думи: под Q1 очаква да има малко данни. Ако са повече става изкривяване.
Под Q2 очаква да има половината данни.
Под Q3 очаква да има 75% от данни
Над Q3 очаква да има малко данни, тъй като е нормално разпределение.

Пример, как изглеждат данни с разпределение различно от нормалното:
library(UsingR)
data(faithful)
hist(faithful$eruptions)
qqnorm(faithful$eruptions, main='faithful eruptions')
qqline(faithful$eruptions)
Тук данните не са в права линия, което индикира че не са нормално разпределение. 

Методите на око, служат повече за ориентир, отколкото за краен извод. Те не са статистически обосновани и нямат висока стойност.

Начин 2, статистически подход:
Прилагаме тест на Шапиро.
Тестът проверява дали данните следват нормално разпределение. Резултат е p-value. Нулевата хипотеза е, че следват. Алтернативната е, че не следват.
shapiro.test(x)
	Shapiro-Wilk normality test

data:  x
W = 0.98781, p-value = 0.9659

Интерпретация:
p-value >= 0.05, следователно данните следват нормално разпределение и може да приложим спокойно t.test

Начин 3, спрямо същността на данните:
Стойностите, които имаме са измерване на височини. Височината в природата на Земята е с нормално разпределение.

t.test(x, mu=15.7, alt='less')
Нулевата хипотеза е, че средното ще е 15.7
Алтернативната хипотеза е, че средното ще е по-малко от 15.7
p-value = 0.00003174, следователно приемаме алтернативната хипотеза и заключението ни е, че третирането е дало желаният резултат.

Oще малко за начин 3, спрямо същността на данните:
Стойностите, които имаме са измерване на височини. Височината в природата на Земята е с нормално разпределение.
При малка и/или неподходяща извадка, може данните да са нормално разпределени по същност, но всички останали методи да покажат, че не са.

Пример с височина на хора, с малка, неподходяща извадка:
x <- scan()
159 160 161 160.5 185 185.2 193
hist(x)

qqnorm(x,main='Example 02'); 
qqline(x)
Може и да е, може и да не е..

shapiro.test(x)

	Shapiro-Wilk normality test

data:  x
W = 0.77155, p-value = 0.02119

Шапиро, пък казва, че не са нормално разпределени..
Какво правим?

=======
Метод за тестване на хипотези, когато данните не са нормално разпределени.
wilcox.test -> метод, който не използва средното за оценка, а използва медианата. 
Медианата не е чувствителна към outlier-и, за разлика от средното.

Пример:
Нека имаме 8 деца участващи в изследване. Изследването представлява третирането на дечицата с дадено вещество и цели да покаже, дали то влияе на резултатите от тестовете.
Преди изследването са показали следните резултати:
x <- scan()
85 15 80 65 80 75 55 20 10 10 90
Седмица след третирането им с даденото вещество, дават следните резултати:
y <- scan()
75 20 50 40 20 65 40 25 20 20 30

За да решим задачата, трябва да минем през няколко стъпки.
1. Да проверим разпределението на данните
2. Да намерим средния на броя точки, преди третирането. (то ще ни служи за построяване на нулева хипотеза)
3. Да пуснем тест, който проверява дали средния брой точки се е изместил.

shapiro.test(x)
mean(x)
wilcox.test(y, mu=mean(x) )

Извод:
Лекарството има ефект, но не знаем дали е повишил или занижил резултатите.
Как да проверим дали ги е понижил или завишил?

-------Тестване на хипотези между две променливи-------   Two sample tests
Two sample tests се ползват за сравняване на едни данни, срещу други данни.
С други думи, дали има разлика преди(една променлива) и след (друга променлива)

Ползват се същите функции prop.test, t.test, wilcox.test, но по различен начин.

Задача:
Фирма прави проучване в университет, под формата на запитване на студенти, дали харесват даден продукт (например душ-гел).
45 отговорили положително
35 отговорили отрицателно
След запитването, фирмата поставила рекламна табела във висшето учебно заведение и след седмица провела отново същото запитване, за рекламирания продукт. Резултатът бил:
56 отговорили положително
47 отговорили отрицателно

Фирмата се зачудила, дали рекламата ѝ реално е имала резултат и се допитала до нас.

За да отговорим на въпроса на фирмата прилагаме two sample test за пропорции.
prop.test( c(45, 56), c(45+35, 56+47) )

	2-sample test for equality of proportions with continuity correction

data:  c(45, 56) out of c(45 + 35, 56 + 47)
X-squared = 0.010813, df = 1, p-value = 0.9172
alternative hypothesis: two.sided
95 percent confidence interval:
 -0.1374478  0.1750692
sample estimates:
   prop 1    prop 2 
0.5625000 0.5436893 

Нулевата хипотеза е, че пропорцията харесали/нехаресали е еднакви при първите данни и при вторите данни (преди и след поставянето на рекламата)
Алтернативната е, че има промяна, макар и незнайна в коя посока.

p-value=0.9172, следователно приемаме нулевата хипотеза, която гласи, че няма зависимост между поставянето на реклама и избора на студентите.

*two-sample t-tests*
Нека имаме изследване, в което се тества ново лекарство върху група от пациенти. Лекарството цели да ускори времето, за което пациент бива излекуван.
Изследването е направено върху 2 групи хора.
Другите са третирани с лекарството:
with drug: 15 10 13 7 9 8 21 9 14 8 
Първите са взимали placebo и са показали следните резултати:
placebo: 15 14 12 8 14 7 16 10 15 12

Проверяваме дали данните (всяка по отделно) са нормално разпределени.
x <- scan()
15 10 13 7 9 8 21 9 14 8
y <- scan()
15 14 12 8 14 7 16 10 15 12
shapiro.test(x)
shapiro.test(y)
Ако са нормално разпределени, може спокойно да приложим t.test
t.test(x,y,alt="less", var.equal=TRUE)
*var.equal=TRUE се налага, тъй като се предполага, че 2те разпределения ще имат еднаква дисперсия.

p-value > 0.05 съответно, приемаме нулевата хипотеза.
Нулевата хипотеза е, че 2те разпределения имат еднакви средни.
Алтернативната е, че данните drugs имат по-малко средно.

*two-sample matched test*
Когато двете извадки, с които работим са зависими се прилага 'matched' тест.

Пример:
Студенти са правили изпит. За по-обективно оценяване всяка работа, бива разгледана от 2ма изпитващи.
Въпросът, на който трябва си отговорим е: 
Има ли разлика в оценяването от изпитващите?

Резултати при 1ви и 2ри изпитващ:
3 0 5 2 5 5 5 4 4 5
2 1 4 1 4 3 3 2 3 5

Проверяваме дали 2те множества от данни са нормално разпределени.
shapiro.test(x)
shapiro.test(y)

wilcox.test(x,y,paired=TRUE)
p-value < 0.05, следователно оценяването при двамата изпитващи не е еднакво.
*Това, което прави резултати на изпитващ 1 и изпитващ 2 зависими е, че оценяват едни и същи работи.
